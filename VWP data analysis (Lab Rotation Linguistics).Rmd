---
title: "VWP data analysis (Lab Rotation Linguistics)"
author: "Ruohan Gao"
date: "2025-04-29"
output: html_document
---

```{r setup wd, include=FALSE} 
setwd("~Lab_modality_data")

```


```{r setup}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, 
                      message = FALSE, cache = TRUE)

# load packages 
library(mgcv)
library(itsadug)
library(sp) # for colors which also print well in grayscale
library(lme4)
library(ggplot2)
library(reshape2)
library(plyr)
library(dplyr)
library(mgcv)
library(magrittr)
library(knitr)
library(tidyverse)
library(forcats)
require(car)
require(lsmeans)
library(MASS)
library(lmerTest)

```


```{r load data}
vwp = read.csv("vwp_data.csv")
vwp$Accuracy = ifelse(vwp$IMAGE_CLICKED == "TARGET", 1, 0)
prop.table(table(vwp$Accuracy))

vwp$proficiency = cut_number(vwp$actual_lextale,2)
prop.table(table(vwp$proficiency))
levels(vwp$proficiency) = c("low","high")
table(vwp$proficiency)

Acc_prof_type = ddply(vwp, .(type,proficiency), summarise,
                      mean_Accuracy = mean(Accuracy))
```
# Accuracy
```{r Accuracy percentage}
Incorrect = cat("data removed = ", round(prop.table(table(vwp$Accuracy))[1]*100, 2),"%, ")

Accuracy = cat("Accuracy = ", round(prop.table(table(vwp$Accuracy))[2]*100, 2),"%")
```

```{r plotting Accuracy}
ggplot(data = Acc_prof_type, aes(x = proficiency, y = mean_Accuracy, color = type, group = type)) +
  geom_line(size = 1) +  # Ensure line is thick enough
  geom_point(size = 3) +  # Make points visible
  scale_x_discrete(labels = c("Low", "High")) +
  scale_color_discrete(labels = c("Predictable", "Unpredictable")) +
  theme_minimal() + 
  labs(
    title = "Mean Accuracy by Proficiency",
    x = "Proficiency",
    y = "Accuracy",
    color = "Type"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 18),
    legend.title = element_text(size = 15, face = "bold"),
    legend.text = element_text(size = 15)
  )
```

```{r glmer Accuracy model}
glmacc = glmer(Accuracy ~ type*proficiency
                + (1 | RECORDING_SESSION_LABEL) +(1|real_item ), 
                family="binomial", control=glmerControl(calc.derivs=FALSE), data=vwp)
anova(glmacc, test = "Chisq")
summary(glmacc)
pairs(emmeans(glmacc, ~ type*proficiency, adjust="tukey"))
```

```{r glm}
glm_acc = glm(Accuracy ~ type*proficiency, family="binomial", data=vwp)
anova(glm_acc)
summary(glm_acc)
pairs(emmeans(glm_acc, ~ type*proficiency, adjust="tukey"))
```

# Plot fixation curves from trial onset
```{r Time course of fixations}
# New data frame: remove incorrectly answered items
vwpacc = vwp[vwp$IMAGE_CLICKED == "TARGET",]
aggregate(data = vwpacc, RECORDING_SESSION_LABEL ~ proficiency,
          function(x) length(unique(x)))

# set up aesthetic parameters for plotting
onsets             <- c(94, 706, 1438)
labelobject = c("Target" = "Guitar", "Anom_Verb" = "Cards",
                "Distract1_agent" = "Microphone","distract2_distract" = "Strawberry")
labeltype = c("predictable" = "Predictable", "unpredictable" = "Unpredictable")
labelproficiency = c("low" = "Low proficiency", "high" = "High proficiency")
labelimage = c("Target"= "Guitar","Verb Related" = "Cards","Agent Related"= "Microphone", "Distractor" = "Strawberry")
```

# Fixation curves
```{r fancy plot}
vwp_p_first <- vwpacc %>% 
  # extract the critical window
  subset(between(time, 0, 2200)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object, type, proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # discard unwanted factor levels
  droplevels()


vwp_p_first$Image<-ifelse(vwp_p_first$object=="Target", "Target",
                                  ifelse(vwp_p_first$object=="Anom_Verb","Verb Related",
                                         ifelse(vwp_p_first$object=="Distract1_agent","Agent Related", "Distractor")))

vwp_p_first$Image<-factor(vwp_p_first$Image, levels = c("Target","Verb Related" ,"Agent Related", "Distractor"))

vwp_p_first$proficiency<-factor(vwp_p_first$proficiency, levels = c("high","low"))

fancy_plot = ggplot(vwp_p_first, aes(x = time, y = MeanFixation)) +
  # plot the mean fixation proportions by region as a line
  stat_summary(fun = mean, geom = "path", 
               aes(group = Image, colour = Image, linetype = Image), 
               linewidth = .7) +
  #add a confidence interval
  stat_summary(fun.data=mean_cl_boot, aes(fill = Image), 
               geom = "ribbon", alpha = .2) +
  ylab("Fixation proportion")+
  xlab("Time (ms)")+
  scale_color_discrete(labels = labelimage, name="") +
  scale_linetype_discrete(labels = labelimage, name="") +
  scale_fill_discrete(labels = labelimage, name="") +
  facet_grid(type~proficiency,
             labeller = labeller(
               proficiency = labelproficiency,
               type = labeltype
             )) +
  geom_vline(xintercept=onsets, linetype="dashed", size = 1, colour="darkgrey") +
  annotate("text", x=onsets[1]-65, y=.5, label="italic(Agent)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[2]-65, y=.5, label="italic(Verb)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[3]-65, y=.5, label="italic(Target)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  theme_light() +
  theme(text = element_text(size = 16),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        strip.text = element_text(size = 16))
fancy_plot
```


# Analyze predictable only
```{r prepare data}

vwp_p<-droplevels(subset(vwp, vwp$type=="predictable"))
vwp_p_correct<-droplevels(subset(vwp_p, vwp_p$IMAGE_CLICKED=="TARGET"))

aggregate(data = vwp_p_correct, RECORDING_SESSION_LABEL ~ proficiency,
          function(x) length(unique(x)))
```


```{r bootstrap time course}
vwp_prediction <- vwp_p_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object,type,proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # discard unwanted factor levels
  droplevels()


vwp_p_first$Image<-ifelse(vwp_p_first$object=="Target", "Target",
                                  ifelse(vwp_p_first$object=="Anom_Verb","Verb Related",
                                         ifelse(vwp_p_first$object=="Distract1_agent","Agent Related", "Distractor")))

vwp_p_first$Image<-factor(vwp_p_first$Image, levels = c("Target","Verb Related" ,"Agent Related", "Distractor"))

vwp_prediction <- vwp_p_correct %>%
  subset(between(time, 0, 2000)) %>%
  # create stratification variables
  mutate(StrataVars = paste(RECORDING_SESSION_LABEL, object, time, proficiency, sep = " ")) %>%
  # drop unwanted factor levels
  droplevels() 

# Convert variables to factors (if bootstrap gives strange errors, not factorizing is a likely cause)
vwp_prediction$StrataVars <- as.factor(vwp_prediction$StrataVars)
vwp_prediction$Time <- as.factor(vwp_prediction$time)
```

# First stage
```{r set up function}
boot_asso_vwp_p_correct <- function(original_data, resample_indices) {
  
  # Resample the data 
  dat_resample <- original_data[resample_indices,]
  
  # Prepare the resampled data for testing 
  dat <- dat_resample %>%
    filter(value == 1 & object %in% c("Target","Anom_Verb")) %>%
    mutate(pTarget = ifelse(object=="Target", 1, 0)) %>%
    # average fixation proportions by participant and time, keeping speaker group
    group_by(RECORDING_SESSION_LABEL, time, proficiency) %>%
    summarise(MeanFixation=mean(pTarget))
  
  # Apply a statistical test at each timepoint for each group
  # Test for low proficiency
  test_lowp <- dat %>%
    subset(proficiency=="low") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Test for high proficiency
  test_highp <- dat %>%
    subset(proficiency=="high") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Return a TRUE/FALSE vector of significant positive t scores
  # positive means more looks to target rather than distractor
  t_lp <- test_lowp$t > 1.96
  t_hp <- test_highp$t > 1.96
  
  # create empty vectors to store onsets
  onset_lp <- onset_hp <- c()
  
  # find the index of the earliest run of 10 sequential TRUEs
  for(i in 1:(length(t_hp)-10)) {
    onset_lp[i] <- sum(t_lp[i:(i+9)]) == 10
    onset_hp[i] <- sum(t_hp[i:(i+9)]) == 10
  }
  
  delta_lp_hp<- which(onset_hp)[1] - which(onset_lp)[1]
  
  c(
    delta_lp_hp, ## onset difference OA vs. YA scot t[,1]
    which(onset_lp)[1], #onset YA scot is t2
    which(onset_hp)[1]  #onset OA is t3
  )
  
  
}

Niter <- 2000
progress = progress::progress_bar$new(total=Niter+1, clear=F, format="[:bar] :percent :eta") # initialise the progress bar
```

```{r this takes long}
bootres_lp_hp <- boot::boot(
  # dataset to bootstrap
  data = vwp_prediction,        
  # bootstrap function                          
  statistic = boot_asso_vwp_p_correct,       
  # stratification variable                          
  strata = vwp_prediction$StrataVars, 
  # number of iterations                          
  R = Niter) 
```

```{r output data}
# Find the mean for the first column (difference in divergence points)
(mean(bootres_lp_hp$t[,1], na.rm=TRUE))*20

# Compute confidence intervals for difference
boot::boot.ci(bootres_lp_hp, index=1, type="perc")$percent[4:5]*20 

(mean(bootres_lp_hp$t[,2], na.rm = TRUE)-1) * 20 #onset OAA is t2
boot::boot.ci(bootres_lp_hp, index=2, type="perc")$percent[4:5]*20 # OA

(mean(bootres_lp_hp$t[,3], na.rm = TRUE)-1) * 20 #onset of YA is t3
boot::boot.ci(bootres_lp_hp, index=3, type="perc")$percent[4:5]*20 # YA
```

```{r plot1 data}
####
dat_plot <- vwp_p_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object, proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # extract the two regions of interest
  subset(object %in% c("Target","Anom_Verb")) %>%
  # discard unwanted factor levels
  droplevels()


dat_plot$Image<-ifelse(dat_plot$object=="Anom_Verb", "Verb Related","Target")
```

```{r graph p1}
# Create plot "p" with Time on the x-axis and mean fixations on the y-axis
p1 <- ggplot(dat_plot, aes(x = time, y = MeanFixation)) +
  coord_cartesian(ylim = c(0, 0.65)) +
  # plot the mean fixation proportions by region as a line
  stat_summary(fun = mean, geom = "path", 
               aes(group = Image, colour = Image, linetype = Image), 
               size = .7) +
  # add a confidence interval
  stat_summary(fun.data=mean_cl_boot, aes(fill = Image), 
               geom = "ribbon", alpha = .2) +
  scale_color_manual(values = c("#F8766D","#7CAE00"), labels = labelimage, name="") +
  scale_fill_manual(values = c("#F8766D","#7CAE00"), labels = labelimage, name="") +
  ylab("Fixation propotion")+
  xlab("Time (ms)")+
  scale_linetype_discrete(labels = labelimage, name="") +
  facet_grid(proficiency~.,
             labeller = labeller(
               proficiency = labelproficiency
             )) +
  theme(strip.text.x = element_text(size = 18))+
  theme(strip.text.y = element_text(size = 18))+
  geom_vline(xintercept=onsets, linetype="dashed", size = 1, colour="darkgrey") +
  annotate("text", x=onsets[1]-35, y=.55, label="italic(Agent)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[2]-30, y=.55, label="italic(Verb)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[3]-40, y=.55, label="italic(Target)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  theme_light() 


p1 +
  theme(text = element_text(size = 16),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        strip.text = element_text(size = 16)) +
  geom_point(data = subset(dat_plot, proficiency == "high"), 
             aes(x = (mean(bootres_lp_hp$t[,3], na.rm = TRUE)-1)*20, y = .25), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot, proficiency == "high"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp, index = 3, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp, index = 3, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .25), height = .1, size = .5) +
  geom_point(data = subset(dat_plot, proficiency == "low"), 
             aes(x = (mean(bootres_lp_hp$t[,2], na.rm = TRUE)-1)*20, y = .25), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot, proficiency == "low"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp, index = 2, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp, index = 2, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .25), height = .1, size = .5)

```

## Second stage
```{r set up function2}
boot_asso_vwp_p2_correct <- function(original_data, resample_indices) {
  
  # Resample the data 
  dat_resample <- original_data[resample_indices,]
  
  # Prepare the resampled data for testing 
  dat <- dat_resample %>%
    filter(value == 1 & object %in% c("Target","Distract1_agent")) %>%
    mutate(pTarget = ifelse(object=="Target", 1, 0)) %>%
    # average fixation proportions by participant and time, keeping speaker group
    group_by(RECORDING_SESSION_LABEL, time, proficiency) %>%
    summarise(MeanFixation=mean(pTarget))
  
  # Apply a statistical test at each timepoint for each group
  # Test for low proficiency
  test_lowp <- dat %>%
    subset(proficiency=="low") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Test for high proficiency
  test_highp <- dat %>%
    subset(proficiency=="high") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Return a TRUE/FALSE vector of significant positive t scores
  # positive means more looks to target rather than distractor
  t_lp <- test_lowp$t > 1.96
  t_hp <- test_highp$t > 1.96
  
  # create empty vectors to store onsets
  onset_lp <- onset_hp <- c()
  
  # find the index of the earliest run of 10 sequential TRUEs
  for(i in 1:(length(t_hp)-10)) {
    onset_lp[i] <- sum(t_lp[i:(i+9)]) == 10
    onset_hp[i] <- sum(t_hp[i:(i+9)]) == 10
  }
  
  delta_lp_hp<- which(onset_hp)[1] - which(onset_lp)[1]
  
  c(
    delta_lp_hp, ## onset difference OA vs. YA scot t[,1]
    which(onset_lp)[1], #onset YA scot is t2
    which(onset_hp)[1]  #onset OA is t3
  )
  
  
}

Niter <- 2000
progress = progress::progress_bar$new(total=Niter+1, clear=F, format="[:bar] :percent :eta") # initialise the progress bar
```

```{r this takes long2}
bootres_lp_hp2 <- boot::boot(
  # dataset to bootstrap
  data = vwp_prediction,        
  # bootstrap function                          
  statistic = boot_asso_vwp_p2_correct,       
  # stratification variable                          
  strata = vwp_prediction$StrataVars, 
  # number of iterations                          
  R = Niter) 
```


```{r output data2}
# Find the mean for the first column (difference in divergence points)
(mean(bootres_lp_hp2$t[,1], na.rm=TRUE))*20

# Compute confidence intervals for difference
boot::boot.ci(bootres_lp_hp2, index=1, type="perc")$percent[4:5]*20 

(mean(bootres_lp_hp2$t[,2], na.rm = TRUE)-1) * 20 #onset lp is t2
boot::boot.ci(bootres_lp_hp2, index=2, type="perc")$percent[4:5]*20 # OA

(mean(bootres_lp_hp2$t[,3], na.rm = TRUE)-1) * 20 #onset of YA is t3
boot::boot.ci(bootres_lp_hp2, index=3, type="perc")$percent[4:5]*20 # YA
```


```{r plot2 data}
dat_plot2 <- vwp_p_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object, proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # extract the two regions of interest
  subset(object %in% c("Target","Distract1_agent")) %>%
  # discard unwanted factor levels
  droplevels()


dat_plot2$Image<-ifelse(dat_plot2$object=="Distract1_agent", "Agent Related","Target")
dat_plot2$Image <- factor(dat_plot2$Image,
                             levels = c("Target", "Agent Related"))
```

```{r graph p2}
# Create plot "p" with Time on the x-axis and mean fixations on the y-axis
p2 <- ggplot(dat_plot2, aes(x = time, y = MeanFixation)) +
  coord_cartesian(ylim = c(0, 0.65)) +
  # plot the mean fixation proportions by region as a line
  stat_summary(fun = mean, geom = "path", 
               aes(group = Image, colour = Image, linetype = Image), 
               size = .7) +
  # add a confidence interval
  stat_summary(fun.data=mean_cl_boot, aes(fill = Image), 
               geom = "ribbon", alpha = .2) +
  scale_color_manual(values = c("#F8766D","#00BFC4"), labels = labelimage, name="") +
  scale_fill_manual(values = c("#F8766D","#00BFC4"), labels = labelimage, name="") +
  ylab("Fixation propotion")+
  xlab("Time (ms)")+
  scale_linetype_discrete(labels = labelimage, name="") +
  facet_grid(proficiency~.,
             labeller = labeller(
               proficiency = labelproficiency
             )) +
  theme(strip.text.x = element_text(size = 18))+
  theme(strip.text.y = element_text(size = 18))+
  geom_vline(xintercept=onsets, linetype="dashed", size = 1, colour="darkgrey") +
  annotate("text", x=onsets[1]-35, y=.55, label="italic(Agent)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[2]-30, y=.55, label="italic(Verb)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[3]-40, y=.55, label="italic(Target)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  theme_light() 


p2 +
  theme(text = element_text(size = 16),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        strip.text = element_text(size = 16)) +
  geom_point(data = subset(dat_plot2, proficiency == "high"), 
             aes(x = (mean(bootres_lp_hp2$t[,3], na.rm = TRUE)-1)*20, y = .33), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot2, proficiency == "high"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp2, index = 3, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp2, index = 3, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .33), height = .1, size = .5) +
  geom_point(data = subset(dat_plot2, proficiency == "low"), 
             aes(x = (mean(bootres_lp_hp2$t[,2], na.rm = TRUE)-1)*20, y = .33), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot2, proficiency == "low"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp2, index = 2, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp2, index = 2, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .33), height = .1, size = .5)
```

# Analyze unpredictable

```{r prepare data}

vwp_unp<-droplevels(subset(vwp, vwp$type=="unpredictable"))
vwp_unp_correct<-droplevels(subset(vwp_unp, vwp_unp$IMAGE_CLICKED=="TARGET"))

aggregate(data = vwp_unp_correct, RECORDING_SESSION_LABEL ~ proficiency,
          function(x) length(unique(x)))
```


```{r bootstrap time course}
vwp_un_prediction <- vwp_unp_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object,type,proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # discard unwanted factor levels
  droplevels()

vwp_un_prediction <- vwp_unp_correct %>%
  subset(between(time, 0, 2000)) %>%
  # create stratification variables
  mutate(StrataVars = paste(RECORDING_SESSION_LABEL, object, time, proficiency, sep = " ")) %>%
  # drop unwanted factor levels
  droplevels() 

# Convert variables to factors (if bootstrap gives strange errors, not factorizing is a likely cause)
vwp_un_prediction$StrataVars <- as.factor(vwp_un_prediction$StrataVars)
vwp_un_prediction$Time <- as.factor(vwp_un_prediction$time)
```

# First stage
```{r set up function}
boot_asso_vwp_p_correct <- function(original_data, resample_indices) {
  
  # Resample the data 
  dat_resample <- original_data[resample_indices,]
  
  # Prepare the resampled data for testing 
  dat <- dat_resample %>%
    filter(value == 1 & object %in% c("Target","Anom_Verb")) %>%
    mutate(pTarget = ifelse(object=="Target", 1, 0)) %>%
    # average fixation proportions by participant and time, keeping speaker group
    group_by(RECORDING_SESSION_LABEL, time, proficiency) %>%
    summarise(MeanFixation=mean(pTarget))
  
  # Apply a statistical test at each timepoint for each group
  # Test for low proficiency
  test_lowp <- dat %>%
    subset(proficiency=="low") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Test for high proficiency
  test_highp <- dat %>%
    subset(proficiency=="high") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Return a TRUE/FALSE vector of significant positive t scores
  # positive means more looks to target rather than distractor
  t_lp <- test_lowp$t > 1.96
  t_hp <- test_highp$t > 1.96
  
  # create empty vectors to store onsets
  onset_lp <- onset_hp <- c()
  
  # find the index of the earliest run of 10 sequential TRUEs
  for(i in 1:(length(t_hp)-10)) {
    onset_lp[i] <- sum(t_lp[i:(i+9)]) == 10
    onset_hp[i] <- sum(t_hp[i:(i+9)]) == 10
  }
  
  delta_lp_hp<- which(onset_hp)[1] - which(onset_lp)[1]
  
  c(
    delta_lp_hp, ## onset difference LowP vs. HighP scot t[,1]
    which(onset_lp)[1], #onset HighP is t2
    which(onset_hp)[1]  #onset LowP is t3
  )
  
  
}

Niter <- 2000
progress = progress::progress_bar$new(total=Niter+1, clear=F, format="[:bar] :percent :eta") # initialise the progress bar
```

```{r this takes long 3}
bootres_lp_hp3 <- boot::boot(
  # dataset to bootstrap
  data = vwp_un_prediction,        
  # bootstrap function                          
  statistic = boot_asso_vwp_p_correct,       
  # stratification variable                          
  strata = vwp_un_prediction$StrataVars, 
  # number of iterations                          
  R = Niter) 
```

```{r output data}
# Find the mean for the first column (difference in divergence points)
(mean(bootres_lp_hp3$t[,1], na.rm=TRUE))*20

# Compute confidence intervals for difference
boot::boot.ci(bootres_lp_hp3, index=1, type="perc")$percent[4:5]*20 

(mean(bootres_lp_hp3$t[,2], na.rm = TRUE)-1) * 20 #onset LowP is t2
boot::boot.ci(bootres_lp_hp3, index=2, type="perc")$percent[4:5]*20 # LowP

(mean(bootres_lp_hp3$t[,3], na.rm = TRUE)-1) * 20 #onset of HighP is t3
boot::boot.ci(bootres_lp_hp3, index=3, type="perc")$percent[4:5]*20 # HighP
```

```{r plot1 data}
####
dat_plot3 <- vwp_unp_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object, proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # extract the two regions of interest
  subset(object %in% c("Target","Anom_Verb")) %>%
  # discard unwanted factor levels
  droplevels()


dat_plot3$Image<-ifelse(dat_plot3$object=="Anom_Verb", "Verb Related","Target")
```

```{r graph p3}
# Create plot "p" with Time on the x-axis and mean fixations on the y-axis
p3 <- ggplot(dat_plot3, aes(x = time, y = MeanFixation)) +
  coord_cartesian(ylim = c(0, 0.65)) +
  # plot the mean fixation proportions by region as a line
  stat_summary(fun = mean, geom = "path", 
               aes(group = Image, colour = Image, linetype = Image), 
               size = .7) +
  # add a confidence interval
  stat_summary(fun.data=mean_cl_boot, aes(fill = Image), 
               geom = "ribbon", alpha = .2) +
  scale_color_manual(values = c("#F8766D","#7CAE00"), labels = labelimage, name="") +
  scale_fill_manual(values = c("#F8766D","#7CAE00"), labels = labelimage, name="") +
  ylab("Fixation propotion")+
  xlab("Time (ms)")+
  scale_linetype_discrete(labels = labelimage, name="") +
  facet_grid(proficiency~.,
             labeller = labeller(
               proficiency = labelproficiency
             )) +
  theme(strip.text.x = element_text(size = 18))+
  theme(strip.text.y = element_text(size = 18))+
  geom_vline(xintercept=onsets, linetype="dashed", size = 1, colour="darkgrey") +
  annotate("text", x=onsets[1]-35, y=.55, label="italic(Agent)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[2]-30, y=.55, label="italic(Verb)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[3]-40, y=.55, label="italic(Target)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  theme_light() 


p3 +
  theme(text = element_text(size = 16),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        strip.text = element_text(size = 16)) +
  geom_point(data = subset(dat_plot3, proficiency == "high"), 
             aes(x = (mean(bootres_lp_hp3$t[,3], na.rm = TRUE)-1)*20, y = .25), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot3, proficiency == "high"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp3, index = 3, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp3, index = 3, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .25), height = .1, size = .5) +
  geom_point(data = subset(dat_plot3, proficiency == "low"), 
             aes(x = (mean(bootres_lp_hp3$t[,2], na.rm = TRUE)-1)*20, y = .25), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot3, proficiency == "low"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp3, index = 2, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp3, index = 2, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .25), height = .1, size = .5)

```

## Second stage
```{r set up function2}
boot_asso_vwp_p2_correct <- function(original_data, resample_indices) {
  
  # Resample the data 
  dat_resample <- original_data[resample_indices,]
  
  # Prepare the resampled data for testing 
  dat <- dat_resample %>%
    filter(value == 1 & object %in% c("Target","Distract1_agent")) %>%
    mutate(pTarget = ifelse(object=="Target", 1, 0)) %>%
    # average fixation proportions by participant and time, keeping speaker group
    group_by(RECORDING_SESSION_LABEL, time, proficiency) %>%
    summarise(MeanFixation=mean(pTarget))
  
  # Apply a statistical test at each timepoint for each group
  # Test for low proficiency
  test_lowp <- dat %>%
    subset(proficiency=="low") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Test for high proficiency
  test_highp <- dat %>%
    subset(proficiency=="high") %>%
    group_by(time) %>%
    summarise(t=t.test(MeanFixation, mu=.5)$statistic[[1]])
  
  # Return a TRUE/FALSE vector of significant positive t scores
  # positive means more looks to target rather than distractor
  t_lp <- test_lowp$t > 1.96
  t_hp <- test_highp$t > 1.96
  
  # create empty vectors to store onsets
  onset_lp <- onset_hp <- c()
  
  # find the index of the earliest run of 10 sequential TRUEs
  for(i in 1:(length(t_hp)-10)) {
    onset_lp[i] <- sum(t_lp[i:(i+9)]) == 10
    onset_hp[i] <- sum(t_hp[i:(i+9)]) == 10
  }
  
  delta_lp_hp<- which(onset_hp)[1] - which(onset_lp)[1]
  
  c(
    delta_lp_hp, ## onset difference LowP vs. YHighP t[,1]
    which(onset_lp)[1], #onset HighP is t2
    which(onset_hp)[1]  #onset LowP is t3
  )
  
  
}

Niter <- 2000
progress = progress::progress_bar$new(total=Niter+1, clear=F, format="[:bar] :percent :eta") # initialise the progress bar
```

```{r this takes long 4}
bootres_lp_hp4 <- boot::boot(
  # dataset to bootstrap
  data = vwp_un_prediction,        
  # bootstrap function                          
  statistic = boot_asso_vwp_p2_correct,       
  # stratification variable                          
  strata = vwp_un_prediction$StrataVars, 
  # number of iterations                          
  R = Niter) 
```


```{r output data2}
# Find the mean for the first column (difference in divergence points)
(mean(bootres_lp_hp4$t[,1], na.rm=TRUE))*20

# Compute confidence intervals for difference
boot::boot.ci(bootres_lp_hp4, index=1, type="perc")$percent[4:5]*20 

(mean(bootres_lp_hp4$t[,2], na.rm = TRUE)-1) * 20 #onset LowP is t2
boot::boot.ci(bootres_lp_hp4, index=2, type="perc")$percent[4:5]*20 # LowP

(mean(bootres_lp_hp4$t[,3], na.rm = TRUE)-1) * 20 #onset of HighP is t3
boot::boot.ci(bootres_lp_hp4, index=3, type="perc")$percent[4:5]*20 # HighP
```


```{r plot4 data}
dat_plot4 <- vwp_unp_correct %>% 
  # extract the critical window
  subset(between(time, 0, 2000)) %>%
  # create mean and sum of fixations by participant, item,
  # timepoint, region and NHLM
  group_by(RECORDING_SESSION_LABEL, time, object, proficiency) %>% 
  summarise(MeanFixation = mean(value),
            SumFixation = sum(value),
            NFixation = length(value)) %>%
  # extract the two regions of interest
  subset(object %in% c("Target","Distract1_agent")) %>%
  # discard unwanted factor levels
  droplevels()


dat_plot4$Image<-ifelse(dat_plot4$object=="Distract1_agent", "Agent Related","Target")
dat_plot4$Image <- factor(dat_plot4$Image,
                             levels = c("Target", "Agent Related"))
```

```{r graph p4}
# Create plot "p" with Time on the x-axis and mean fixations on the y-axis
p4 <- ggplot(dat_plot4, aes(x = time, y = MeanFixation)) +
  coord_cartesian(ylim = c(0, 0.65)) +
  # plot the mean fixation proportions by region as a line
  stat_summary(fun = mean, geom = "path", 
               aes(group = Image, colour = Image, linetype = Image), 
               size = .7) +
  # add a confidence interval
  stat_summary(fun.data=mean_cl_boot, aes(fill = Image), 
               geom = "ribbon", alpha = .2) +
  scale_color_manual(values = c("#F8766D","#00BFC4"), labels = labelimage, name="") +
  scale_fill_manual(values = c("#F8766D","#00BFC4"), labels = labelimage, name="") +
  ylab("Fixation propotion")+
  xlab("Time (ms)")+
  scale_linetype_discrete(labels = labelimage, name="") +
  facet_grid(proficiency~.,
             labeller = labeller(
               proficiency = labelproficiency
             )) +
  theme(strip.text.x = element_text(size = 18))+
  theme(strip.text.y = element_text(size = 18))+
  geom_vline(xintercept=onsets, linetype="dashed", size = 1, colour="darkgrey") +
  annotate("text", x=onsets[1]-35, y=.55, label="italic(Agent)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[2]-30, y=.55, label="italic(Verb)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  annotate("text", x=onsets[3]-40, y=.55, label="italic(Target)",
           parse=TRUE, angle=90, colour="gray45", size=4) +
  theme_light() 


p4 +
  theme(text = element_text(size = 16),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12),
        strip.text = element_text(size = 16)) +
  geom_point(data = subset(dat_plot4, proficiency == "high"), 
             aes(x = (mean(bootres_lp_hp4$t[,3], na.rm = TRUE)-1)*20, y = .33), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot4, proficiency == "high"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp4, index = 3, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp4, index = 3, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .33), height = .1, size = .5) +
  geom_point(data = subset(dat_plot4, proficiency == "low"), 
             aes(x = (mean(bootres_lp_hp4$t[,2], na.rm = TRUE)-1)*20, y = .33), 
             size = 2) + 
  geom_errorbarh(data = subset(dat_plot4, proficiency == "low"),
                 aes(xmin = (boot::boot.ci(bootres_lp_hp4, index = 2, 
                                           type = "perc")$perc[4]-1)*20,
                     xmax = (boot::boot.ci(bootres_lp_hp4, index = 2, 
                                           type = "perc")$perc[5]-1)*20,
                     y = .33), height = .1, size = .5)x



